"""
ë””ë°”ì´ìŠ¤ ê´€ë¦¬ ëª¨ë“ˆ
GPU/CPU ê°ì§€ ë° ì„ íƒ, ìµœì í™”ëœ ë””ë°”ì´ìŠ¤ ê´€ë¦¬ë¥¼ ì œê³µí•©ë‹ˆë‹¤.
"""

import torch
import logging
from typing import Dict, List, Optional, Literal
from dataclasses import dataclass
from enum import Enum

logger = logging.getLogger(__name__)


class DeviceType(str, Enum):
    """ì§€ì›ë˜ëŠ” ë””ë°”ì´ìŠ¤ íƒ€ì…"""
    MPS = "mps"          # Mac Metal Performance Shaders
    CUDA = "cuda"        # NVIDIA GPU
    CPU = "cpu"          # CPU


@dataclass
class DeviceInfo:
    """ë””ë°”ì´ìŠ¤ ì •ë³´"""
    type: DeviceType
    name: str
    is_available: bool
    memory_total: Optional[float] = None      # GB
    memory_allocated: Optional[float] = None  # GB
    memory_reserved: Optional[float] = None   # GB
    compute_capability: Optional[str] = None  # CUDAë§Œ í•´ë‹¹
    
    def to_dict(self) -> Dict:
        """ë”•ì…”ë„ˆë¦¬ë¡œ ë³€í™˜"""
        return {
            "type": self.type.value,
            "name": self.name,
            "is_available": self.is_available,
            "memory_total": self.memory_total,
            "memory_allocated": self.memory_allocated,
            "memory_reserved": self.memory_reserved,
            "compute_capability": self.compute_capability,
        }


class DeviceManager:
    """ë””ë°”ì´ìŠ¤ ê´€ë¦¬ í´ë˜ìŠ¤ (ì‹±ê¸€í†¤ íŒ¨í„´)"""
    
    _instance = None
    _initialized = False
    
    def __new__(cls):
        """ì‹±ê¸€í†¤ íŒ¨í„´"""
        if cls._instance is None:
            cls._instance = super().__new__(cls)
        return cls._instance
    
    def __init__(self):
        """ì´ˆê¸°í™” (í•œ ë²ˆë§Œ ì‹¤í–‰)"""
        if not DeviceManager._initialized:
            self._current_device: Optional[torch.device] = None
            self._selected_device_type: Optional[DeviceType] = None
            self._available_devices: List[DeviceInfo] = []
            self._detect_devices()
            DeviceManager._initialized = True
    
    def _detect_devices(self) -> None:
        """ì‚¬ìš© ê°€ëŠ¥í•œ ëª¨ë“  ë””ë°”ì´ìŠ¤ ê°ì§€"""
        logger.info("ğŸ” ì‹œìŠ¤í…œ ë””ë°”ì´ìŠ¤ ê°ì§€ ì¤‘...")
        
        # 1. MPS (Mac Metal Performance Shaders) ê°ì§€
        if torch.backends.mps.is_available():
            self._available_devices.append(
                DeviceInfo(
                    type=DeviceType.MPS,
                    name="Apple Metal Performance Shaders",
                    is_available=True,
                )
            )
            logger.info("âœ… MPS (Mac GPU) ê°ì§€ë¨")
        
        # 2. CUDA (NVIDIA GPU) ê°ì§€
        if torch.cuda.is_available():
            cuda_count = torch.cuda.device_count()
            for i in range(cuda_count):
                try:
                    props = torch.cuda.get_device_properties(i)
                    total_memory = props.total_memory / (1024 ** 3)  # GBë¡œ ë³€í™˜
                    
                    self._available_devices.append(
                        DeviceInfo(
                            type=DeviceType.CUDA,
                            name=f"{props.name} (ID: {i})",
                            is_available=True,
                            memory_total=total_memory,
                            compute_capability=f"{props.major}.{props.minor}",
                        )
                    )
                    logger.info(f"âœ… CUDA GPU ê°ì§€ë¨: {props.name} ({total_memory:.2f}GB)")
                except Exception as e:
                    logger.warning(f"âš ï¸  CUDA ì •ë³´ ì¡°íšŒ ì‹¤íŒ¨: {e}")
        
        # 3. CPU (í•­ìƒ ì‚¬ìš© ê°€ëŠ¥)
        self._available_devices.append(
            DeviceInfo(
                type=DeviceType.CPU,
                name="CPU (Intel/AMD)",
                is_available=True,
            )
        )
        logger.info("âœ… CPU ê°ì§€ë¨")
        
        logger.info(f"ğŸ“Š ì´ {len(self._available_devices)}ê°œ ë””ë°”ì´ìŠ¤ ê°ì§€ë¨")
    
    def get_available_devices(self) -> List[DeviceInfo]:
        """ì‚¬ìš© ê°€ëŠ¥í•œ ëª¨ë“  ë””ë°”ì´ìŠ¤ ë°˜í™˜"""
        return self._available_devices
    
    def select_device(self, device_type: str) -> bool:
        """ë””ë°”ì´ìŠ¤ ì„ íƒ
        
        Args:
            device_type: ì„ íƒí•  ë””ë°”ì´ìŠ¤ íƒ€ì… ("mps", "cuda", "cpu")
        
        Returns:
            ì„±ê³µ ì—¬ë¶€
        """
        try:
            device_type = device_type.lower()
            
            # ìœ íš¨í•œ íƒ€ì… í™•ì¸
            if device_type not in [d.value for d in DeviceType]:
                logger.error(f"âŒ ì§€ì›í•˜ì§€ ì•ŠëŠ” ë””ë°”ì´ìŠ¤ íƒ€ì…: {device_type}")
                return False
            
            # ì‚¬ìš© ê°€ëŠ¥ ì—¬ë¶€ í™•ì¸
            device_enum = DeviceType(device_type)
            available_device = next(
                (d for d in self._available_devices 
                 if d.type == device_enum and d.is_available),
                None
            )
            
            if not available_device:
                logger.error(f"âŒ ì‚¬ìš© ë¶ˆê°€ëŠ¥í•œ ë””ë°”ì´ìŠ¤: {device_type}")
                return False
            
            # ë””ë°”ì´ìŠ¤ ì„¤ì •
            if device_type == "mps":
                self._current_device = torch.device("mps")
            elif device_type == "cuda":
                self._current_device = torch.device("cuda")
            else:  # cpu
                self._current_device = torch.device("cpu")
            
            self._selected_device_type = device_enum
            logger.info(f"âœ… ë””ë°”ì´ìŠ¤ ì„ íƒ ì™„ë£Œ: {device_type}")
            logger.info(f"ğŸ¯ í˜„ì¬ ë””ë°”ì´ìŠ¤: {self._current_device}")
            
            return True
        
        except Exception as e:
            logger.error(f"âŒ ë””ë°”ì´ìŠ¤ ì„ íƒ ì¤‘ ì˜¤ë¥˜: {e}")
            return False
    
    def get_current_device(self) -> torch.device:
        """í˜„ì¬ ì„ íƒëœ ë””ë°”ì´ìŠ¤ ë°˜í™˜"""
        if self._current_device is None:
            # ê¸°ë³¸ê°’: ìµœì ì˜ ë””ë°”ì´ìŠ¤ ì„ íƒ
            self.auto_select_device()
        return self._current_device
    
    def get_current_device_type(self) -> Optional[DeviceType]:
        """í˜„ì¬ ì„ íƒëœ ë””ë°”ì´ìŠ¤ íƒ€ì… ë°˜í™˜"""
        return self._selected_device_type
    
    def auto_select_device(self) -> bool:
        """ìµœì ì˜ ë””ë°”ì´ìŠ¤ ìë™ ì„ íƒ
        ìš°ì„ ìˆœìœ„: MPS > CUDA > CPU
        """
        logger.info("ğŸ¤– ìµœì  ë””ë°”ì´ìŠ¤ ìë™ ì„ íƒ ì¤‘...")
        
        # MPS ìš°ì„ 
        if any(d.type == DeviceType.MPS and d.is_available for d in self._available_devices):
            return self.select_device("mps")
        
        # CUDA ë‹¤ìŒ
        if any(d.type == DeviceType.CUDA and d.is_available for d in self._available_devices):
            return self.select_device("cuda")
        
        # CPU ìµœí›„
        return self.select_device("cpu")
    
    def move_tensor_to_device(self, tensor: torch.Tensor) -> torch.Tensor:
        """í…ì„œë¥¼ í˜„ì¬ ì„ íƒëœ ë””ë°”ì´ìŠ¤ë¡œ ì´ë™"""
        device = self.get_current_device()
        return tensor.to(device)
    
    def move_model_to_device(self, model: torch.nn.Module) -> torch.nn.Module:
        """ëª¨ë¸ì„ í˜„ì¬ ì„ íƒëœ ë””ë°”ì´ìŠ¤ë¡œ ì´ë™"""
        device = self.get_current_device()
        return model.to(device)
    
    def get_device_memory_info(self) -> Dict:
        """í˜„ì¬ ë””ë°”ì´ìŠ¤ì˜ ë©”ëª¨ë¦¬ ì •ë³´ ë°˜í™˜"""
        device = self.get_current_device()
        
        if device.type == "cuda":
            return {
                "device": str(device),
                "allocated": torch.cuda.memory_allocated(device) / (1024 ** 3),
                "reserved": torch.cuda.memory_reserved(device) / (1024 ** 3),
                "total": torch.cuda.get_device_properties(device.index).total_memory / (1024 ** 3),
            }
        elif device.type == "mps":
            # MPSëŠ” ë©”ëª¨ë¦¬ ì •ë³´ë¥¼ ì œê³µí•˜ì§€ ì•ŠìŒ
            return {
                "device": str(device),
                "allocated": None,
                "reserved": None,
                "total": None,
            }
        else:  # cpu
            return {
                "device": str(device),
                "allocated": None,
                "reserved": None,
                "total": None,
            }
    
    def clear_cache(self) -> None:
        """ë””ë°”ì´ìŠ¤ ìºì‹œ ë©”ëª¨ë¦¬ ì •ë¦¬"""
        device = self.get_current_device()
        
        if device.type == "cuda":
            torch.cuda.empty_cache()
            logger.info("âœ… CUDA ìºì‹œ ì •ë¦¬ ì™„ë£Œ")
        elif device.type == "mps":
            # MPSëŠ” ìˆ˜ë™ ë©”ëª¨ë¦¬ ê´€ë¦¬ ì§€ì›í•˜ì§€ ì•ŠìŒ
            logger.info("â„¹ï¸  MPSëŠ” ìë™ ë©”ëª¨ë¦¬ ê´€ë¦¬ë¥¼ ì‚¬ìš©í•©ë‹ˆë‹¤")
        else:  # cpu
            logger.info("â„¹ï¸  CPUëŠ” ìºì‹œ ì •ë¦¬ê°€ í•„ìš”í•˜ì§€ ì•ŠìŠµë‹ˆë‹¤")
    
    def get_optimal_dtype(self) -> torch.dtype:
        """í˜„ì¬ ë””ë°”ì´ìŠ¤ì— ìµœì í™”ëœ ë°ì´í„° íƒ€ì… ë°˜í™˜"""
        device = self.get_current_device()
        
        if device.type == "cuda":
            # CUDAì—ì„œëŠ” float16 ë˜ëŠ” bfloat16 ê¶Œì¥
            if torch.cuda.is_available() and torch.cuda.get_device_capability(device.index)[0] >= 8:
                return torch.bfloat16  # Ampere ì´ìƒ
            return torch.float16
        elif device.type == "mps":
            # MPSëŠ” float32 ë˜ëŠ” float16 ì§€ì›
            return torch.float32
        else:  # cpu
            return torch.float32
    
    def get_status_info(self) -> Dict:
        """í˜„ì¬ ë””ë°”ì´ìŠ¤ ìƒíƒœ ì •ë³´ ë°˜í™˜"""
        current_device = self.get_current_device()
        memory_info = self.get_device_memory_info()
        
        return {
            "current_device": str(current_device),
            "device_type": current_device.type,
            "available_devices": [d.to_dict() for d in self._available_devices],
            "selected_type": self._selected_device_type.value if self._selected_device_type else None,
            "memory": memory_info,
            "optimal_dtype": str(self.get_optimal_dtype()),
        }


# ì „ì—­ ì¸ìŠ¤í„´ìŠ¤ (ì‹±ê¸€í†¤)
device_manager = DeviceManager()


def get_device_manager() -> DeviceManager:
    """ë””ë°”ì´ìŠ¤ ë§¤ë‹ˆì € ì¸ìŠ¤í„´ìŠ¤ ë°˜í™˜"""
    return device_manager


